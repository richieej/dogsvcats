{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dogs_vs_cats_CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "twHiCwdM1qoZ"
      },
      "source": [
        "#Imports\n",
        "import os #The OS module provides functions for interacting with the operating system. \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "keras = tf.keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ibfxjs1M2Lm2"
      },
      "source": [
        "#import cats_vs_dogs dataset from the modoule tensorflow_datasets\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "# split the data manually into 80% training, 10% testing, 10% validation\n",
        "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hqd7pBu2ons"
      },
      "source": [
        "get_label_name = metadata.features['label'].int2str  \n",
        "# creates a function object that we can use to get labels\n",
        "\n",
        "# display 5 images from the dataset\n",
        "for image, label in raw_train.take(5):\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.title(get_label_name(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6I_Eayx3wim"
      },
      "source": [
        "#data preprocessing: convert all images to the same size\n",
        "\n",
        "IMG_SIZE = 160 # All images will be resized to 160x160\n",
        "\n",
        "def format_example(image, label):\n",
        "  \"\"\"\n",
        "  returns an image that is reshaped to IMG_SIZE\n",
        "  \"\"\"\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = (image/127.5) - 1\n",
        "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMtTTY_r4C5o"
      },
      "source": [
        "#apply this function to all of the images using map()\n",
        "train = raw_train.map(format_example)   #raw_* is how we imported the data\n",
        "validation = raw_validation.map(format_example)\n",
        "test = raw_test.map(format_example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8ji20ql5SuU"
      },
      "source": [
        "#shuffle and batch the images\n",
        "BATCH_SIZE = 32\n",
        "SHUFFLE_BUFFER_SIZE = 1000\n",
        "\n",
        "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "validation_batches = validation.batch(BATCH_SIZE)\n",
        "test_batches = test.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYXN_bmk4tQ6"
      },
      "source": [
        "#picking a pretrained model\n",
        "#here we will use MobileNet V2\n",
        "\n",
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soBcR581539O"
      },
      "source": [
        "#freezing the base\n",
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gko7al26jb-"
      },
      "source": [
        "#adding our classifier\n",
        "\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "#this flattens the layers from the pretrained model (1280 layers of 5x5) into a 1D tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6KtqbPP7CXG"
      },
      "source": [
        "#add prediction layer (1 dense node because we are only predicting 2 classes)\n",
        "prediction_layer = keras.layers.Dense(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db0KE7EI7Tf-"
      },
      "source": [
        "#combine the models and layers into a model\n",
        "model = tf.keras.Sequential([\n",
        "   base_model,\n",
        "   global_average_layer,\n",
        "   prediction_layer                          \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22YfNd577f95"
      },
      "source": [
        "#training the model\n",
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# We can evaluate the model right now to see how it does before training it on our new images\n",
        "initial_epochs = 3\n",
        "validation_steps=20\n",
        "\n",
        "loss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXBs6ovk7qlY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "3f79b26d-981b-4bd1-c8e8-b5e6d6be872d"
      },
      "source": [
        "# Now we can train it on our images\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_batches)\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "582/582 [==============================] - 399s 685ms/step - loss: 0.2406 - accuracy: 0.8873 - val_loss: 0.0896 - val_accuracy: 0.9690\n",
            "Epoch 2/3\n",
            "582/582 [==============================] - 395s 679ms/step - loss: 0.0725 - accuracy: 0.9751 - val_loss: 0.0651 - val_accuracy: 0.9768\n",
            "Epoch 3/3\n",
            "582/582 [==============================] - 397s 681ms/step - loss: 0.0579 - accuracy: 0.9790 - val_loss: 0.0571 - val_accuracy: 0.9802\n",
            "[0.8873186707496643, 0.9751209020614624, 0.9790435433387756]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYyPrAuh8Usn"
      },
      "source": [
        "model.save(\"dogs_vs_cats.h5\")  # we can save the model and reload it at anytime in the future\n",
        "new_model = tf.keras.models.load_model('dogs_vs_cats.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssBpbDQ_9Gea"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}